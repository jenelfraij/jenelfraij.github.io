---
layout: post
title: Blog Post 5
---

In this blog post, we will explore several skills and concepts related to image classification in Tensorflow. We will teach a machine learning algorithm to distinguish between pictures of dogs and pictures of cats with high accuracy.

**Note** that some parts of this blog post are based on code given in the blog post assignment, as well as the TensorFlow Transfer Learning Tutorial.

First, we need to import some useful libraries.


```python
import os
import tensorflow as tf
from tensorflow.keras import utils, layers, models
import matplotlib.pyplot as plt
import numpy as np
```

# §1. Load Packages and Obtain Data

We’ll use a sample data set provided by TensorFlow that contains labeled images of cats and dogs.

We will create TensorFlow `Dataset`s for training, validation, and testing. In this case, we are using a special-purpose `keras` utility called `image_dataset_from_directory` to construct a `Dataset`. We use the `shuffle` argument which says that, when retrieving data from this directory, the order should be randomized. The `batch_size` determines how many data points are gathered from the directory at once. In this case, each time we request some data we will get 32 images from each of the data sets. Finally, the `image_size` specifies the size of the input images.


```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
```

```python
Found 2000 files belonging to 2 classes.
Found 1000 files belonging to 2 classes.
```

We also need the following code, which is related to rapidly reading data.


```python
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```

Now let's explore our data set. We will create a function to make a two-row visualization where the first row has three random pictures of cats, and the second row has three random pictures of dogs.


```python
plt.figure(figsize=(12, 9)) # create empty plot
# use train_dataset.take(1) to retrieve one batch from the training data
for images, labels in train_dataset.take(1):
    for i in range(3):
        # plot cat pictures (label 0)
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[labels == 0][i].numpy().astype("uint8"))
        plt.title('Cat') # label as a cat
        plt.axis("off") # hide axis
        # plot dog pctures (label 1)
        ax = plt.subplot(3, 3, i + 4)
        plt.imshow(images[labels == 1][i].numpy().astype("uint8"))
        plt.title('Dog') # label as a dog
        plt.axis("off") # hide axis
```

![m1.png](/images/m1.png)

Looks good!

## Baseline Model

Now we will create an iterator called labels, then use it to compute the number of images in the training data with label 0 (corresponding to "cat") and label 1 (corresponding to "dog"). This method allows us to have a baseline machine learning model, which always guesses the most frequent label.


```python
# create an iterator
labels_iterator = train_dataset.unbatch().map(lambda image,
                                              label: label).as_numpy_iterator()

s = [] # initialize an empty list to which we append the labels
for label in labels_iterator:
    s.append(label) # append labels
    
# print the accuracy result if we guess the most frequent label
print("Base model accuracy is " + str(max(sum(s), len(s)-sum(s))/len(s)))
```

```python
Base model accuracy is 0.5
```

It looks like the baseline model gives a random chance of making a correct guess (50%), which is not very good. We will try to increase our accuracy by creating more powerful models.

# §2. First Model

Now let's create a `tf.keras.Sequential` model that includes some layers for better accuracy. Here I am using 3 `Conv2D` layers, 3 `MaxPooling2D` layers, 1 `Flatten` layer, 2 `Dense` layers, and 1 `Dropout` layer.


```python
# create model 1
model1 = models.Sequential([
    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(16, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(2) # we have 2 classes
])
```

Let's train our model and see how it does! We will also plot the history of the accuracy on both the training and validation sets.

Training consists of two steps. First we compile the model, by specifying the loss function and optimization algorithm. Then, we perform the actual training. Finally, the `metrics` argument is helpful for controlling which model performance measures are shown when training or evaluating the model.


```python
# compile the model
model1.compile(optimizer='adam',
               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
               metrics=['accuracy'])
# fit the model for training
history1 = model1.fit(train_dataset,
                      epochs = 20, # we use 20 epochs for training
                      validation_data = validation_dataset)
```

```python
Epoch 1/20
63/63 [==============================] - 7s 78ms/step - loss: 12.9214 - accuracy: 0.5390 - val_loss: 0.6856 - val_accuracy: 0.5495
Epoch 2/20
63/63 [==============================] - 5s 76ms/step - loss: 0.5901 - accuracy: 0.6905 - val_loss: 0.7322 - val_accuracy: 0.5842
Epoch 3/20
63/63 [==============================] - 5s 72ms/step - loss: 0.4257 - accuracy: 0.8125 - val_loss: 0.8249 - val_accuracy: 0.5965
Epoch 4/20
63/63 [==============================] - 5s 75ms/step - loss: 0.2643 - accuracy: 0.8910 - val_loss: 0.8781 - val_accuracy: 0.6052
Epoch 5/20
63/63 [==============================] - 5s 74ms/step - loss: 0.1489 - accuracy: 0.9420 - val_loss: 1.2681 - val_accuracy: 0.5978
Epoch 6/20
63/63 [==============================] - 5s 74ms/step - loss: 0.0905 - accuracy: 0.9690 - val_loss: 1.2414 - val_accuracy: 0.6077
Epoch 7/20
63/63 [==============================] - 5s 73ms/step - loss: 0.1064 - accuracy: 0.9650 - val_loss: 1.1444 - val_accuracy: 0.6015
Epoch 8/20
63/63 [==============================] - 5s 73ms/step - loss: 0.1189 - accuracy: 0.9620 - val_loss: 1.3605 - val_accuracy: 0.6064
Epoch 9/20
63/63 [==============================] - 5s 74ms/step - loss: 0.0578 - accuracy: 0.9830 - val_loss: 1.4653 - val_accuracy: 0.5903
Epoch 10/20
63/63 [==============================] - 5s 74ms/step - loss: 0.0477 - accuracy: 0.9840 - val_loss: 1.5292 - val_accuracy: 0.6040
Epoch 11/20
63/63 [==============================] - 5s 74ms/step - loss: 0.0274 - accuracy: 0.9920 - val_loss: 1.7319 - val_accuracy: 0.5928
Epoch 12/20
63/63 [==============================] - 5s 74ms/step - loss: 0.0420 - accuracy: 0.9905 - val_loss: 1.8500 - val_accuracy: 0.5804
Epoch 13/20
63/63 [==============================] - 5s 79ms/step - loss: 0.0310 - accuracy: 0.9915 - val_loss: 1.7995 - val_accuracy: 0.6188
Epoch 14/20
63/63 [==============================] - 5s 77ms/step - loss: 0.0233 - accuracy: 0.9910 - val_loss: 2.2656 - val_accuracy: 0.5953
Epoch 15/20
63/63 [==============================] - 5s 75ms/step - loss: 0.0535 - accuracy: 0.9845 - val_loss: 1.7848 - val_accuracy: 0.5903
Epoch 16/20
63/63 [==============================] - 5s 76ms/step - loss: 0.0600 - accuracy: 0.9835 - val_loss: 1.8201 - val_accuracy: 0.5891
Epoch 17/20
63/63 [==============================] - 5s 73ms/step - loss: 0.0474 - accuracy: 0.9830 - val_loss: 2.1992 - val_accuracy: 0.6040
Epoch 18/20
63/63 [==============================] - 5s 73ms/step - loss: 0.0348 - accuracy: 0.9910 - val_loss: 1.8844 - val_accuracy: 0.6052
Epoch 19/20
63/63 [==============================] - 5s 73ms/step - loss: 0.0403 - accuracy: 0.9890 - val_loss: 1.8304 - val_accuracy: 0.5916
Epoch 20/20
63/63 [==============================] - 5s 73ms/step - loss: 0.0167 - accuracy: 0.9955 - val_loss: 2.2978 - val_accuracy: 0.6040
```


```python
# plot the history of the accuracy on the training and validation sets
plt.plot(history1.history["accuracy"], label = "training")
plt.plot(history1.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```

![m2.png](/images/m2.png)

For this part I tried multiple combinations of layers. The one shown here gave the best accuracy. I originally had 64 units in the `Dense` layer, but increasing the number of units to 128 produced better results.

**The validation accuracy of this model during training ranges between %55 and %62.**

Even through we did not achieve a very good accuracy, it is still a little better than the baseline model by at least %5 more accuracy. However, we can clearly observe overfitting here since the training accuracy, which reaches almost %100, is much higher than the validation accuracy.

# §3. Model with Data Augmentation

Now we’re going to add some data augmentation layers to our model. We do that by including modified copies of the same image in the training set. It is a good idea to include such transformed versions of the image in our training process in order to help our model learn invariant features of our input images.

First we will create a `tf.keras.layers.RandomFlip()` layer.


```python
data_augmentation = tf.keras.Sequential([
  tf.keras.layers.RandomFlip(),
])
```

Now let's take a look at a few copies to which `RandomFlip()` has been applied.


```python
for image, _ in train_dataset.take(1):
    plt.figure(figsize=(10, 10))
    first_image = image[0]
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))
        plt.imshow(augmented_image[0] / 255)
        plt.axis('off')
```

![m3.png](/images/m3.png)

I argue that this wins the cutest dog picture in our dataset!

Next, let's create a `tf.keras.layers.RandomRotation()` layer. We will use a factor of 0.3, which results in an output rotating by a random amount in the range [-30% * 2pi, 30% * 2pi].


```python
data_augmentation = tf.keras.Sequential([
  tf.keras.layers.RandomRotation(0.3),
])
```

Then, we will make a plot of both the original image and a few copies to which `RandomRotation()` has been applied.


```python
for image, _ in train_dataset.take(1):
    plt.figure(figsize=(10, 10))
    first_image = image[0]
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))
        plt.imshow(augmented_image[0] / 255)
        plt.axis('off')
```

![m4.png](/images/m4.png)

Let's put the two data augmentation methods together.


```python
data_augmentation = tf.keras.Sequential([
  tf.keras.layers.RandomFlip(),
  tf.keras.layers.RandomRotation(0.3),
])
```

Now we can create a new `tf.keras.models.Sequential` model in which the first two layers are given by `data_augmentation`. We will train our model, and visualize the training history as we did earlier.


```python
# create model 2
model2 = models.Sequential([
    data_augmentation,
    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(16, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(16, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.1),
    layers.Dense(2)
])
```


```python
# compile model 2
model2.compile(optimizer='adam',
               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
               metrics=['accuracy'])

# train model 2 with 20 epochs
history2 = model2.fit(train_dataset,
                      epochs = 20,
                      validation_data = validation_dataset)
```

```python
Epoch 1/20
63/63 [==============================] - 7s 83ms/step - loss: 1.5485 - accuracy: 0.5205 - val_loss: 0.7115 - val_accuracy: 0.5507
Epoch 2/20
63/63 [==============================] - 5s 77ms/step - loss: 0.6770 - accuracy: 0.5620 - val_loss: 0.6828 - val_accuracy: 0.5817
Epoch 3/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6711 - accuracy: 0.5840 - val_loss: 0.6627 - val_accuracy: 0.6200
Epoch 4/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6689 - accuracy: 0.5850 - val_loss: 0.6582 - val_accuracy: 0.6176
Epoch 5/20
63/63 [==============================] - 5s 75ms/step - loss: 0.6505 - accuracy: 0.6325 - val_loss: 0.6323 - val_accuracy: 0.6498
Epoch 6/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6373 - accuracy: 0.6360 - val_loss: 0.6263 - val_accuracy: 0.6436
Epoch 7/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6404 - accuracy: 0.6245 - val_loss: 0.6489 - val_accuracy: 0.6101
Epoch 8/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6321 - accuracy: 0.6525 - val_loss: 0.6154 - val_accuracy: 0.6696
Epoch 9/20
63/63 [==============================] - 5s 78ms/step - loss: 0.6270 - accuracy: 0.6515 - val_loss: 0.6462 - val_accuracy: 0.6101
Epoch 10/20
63/63 [==============================] - 5s 79ms/step - loss: 0.6218 - accuracy: 0.6595 - val_loss: 0.6657 - val_accuracy: 0.5804
Epoch 11/20
63/63 [==============================] - 5s 77ms/step - loss: 0.6445 - accuracy: 0.6365 - val_loss: 0.6353 - val_accuracy: 0.6609
Epoch 12/20
63/63 [==============================] - 5s 75ms/step - loss: 0.6265 - accuracy: 0.6550 - val_loss: 0.6171 - val_accuracy: 0.6510
Epoch 13/20
63/63 [==============================] - 5s 77ms/step - loss: 0.6211 - accuracy: 0.6610 - val_loss: 0.6377 - val_accuracy: 0.6436
Epoch 14/20
63/63 [==============================] - 5s 75ms/step - loss: 0.6194 - accuracy: 0.6585 - val_loss: 0.6166 - val_accuracy: 0.6621
Epoch 15/20
63/63 [==============================] - 5s 75ms/step - loss: 0.6137 - accuracy: 0.6710 - val_loss: 0.6213 - val_accuracy: 0.6485
Epoch 16/20
63/63 [==============================] - 5s 74ms/step - loss: 0.6132 - accuracy: 0.6605 - val_loss: 0.5817 - val_accuracy: 0.6918
Epoch 17/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6016 - accuracy: 0.6785 - val_loss: 0.6014 - val_accuracy: 0.6448
Epoch 18/20
63/63 [==============================] - 5s 75ms/step - loss: 0.5928 - accuracy: 0.6885 - val_loss: 0.5997 - val_accuracy: 0.6658
Epoch 19/20
63/63 [==============================] - 5s 75ms/step - loss: 0.5929 - accuracy: 0.6675 - val_loss: 0.5920 - val_accuracy: 0.6993
Epoch 20/20
63/63 [==============================] - 5s 77ms/step - loss: 0.5790 - accuracy: 0.6970 - val_loss: 0.5757 - val_accuracy: 0.6943
```

```python
# plot the history of the accuracy on the training and validation sets
plt.plot(history2.history["accuracy"], label = "training")
plt.plot(history2.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```

![m5.png](/images/m5.png)

**The validation accuracy of this model during training ranges between %55 and %70.**

This model seems to perform a little better than model1 as to reaches a validation accuracy of about %70 while model1 only reached %62. In addition to that, it looks like this model does not overfit. We can see that the training accuracy and the validation accuracy are in the same range.

# §4. Data Preprocessing

Another helpful tool to increase our validation accuracy is making simple transformations to the input data. Normalizing RGB values will help our model train faster.

In the following code we create a preprocessing layer called `preprocessor` which we will add to our model pipeline.


```python
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])
```

Now we can create a new `tf.keras.models.Sequential` model where we add the `preprocessor` layer. We will train our model, and visualize the training history as we did before.


```python
# create model 3
model3 = models.Sequential([
    preprocessor,
    data_augmentation,
    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(16, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(16, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.1),
    layers.Dense(2) # number of classes
])
```


```python
# compile model 3
model3.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
# train model 3 with 20 epochs
history3 = model3.fit(train_dataset, 
                    =20, 
                     validation_data = validation_dataset)
```

```python
Epoch 1/20
63/63 [==============================] - 6s 80ms/step - loss: 0.6879 - accuracy: 0.5390 - val_loss: 0.6673 - val_accuracy: 0.5965
Epoch 2/20
63/63 [==============================] - 5s 75ms/step - loss: 0.6682 - accuracy: 0.5815 - val_loss: 0.6330 - val_accuracy: 0.6374
Epoch 3/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6250 - accuracy: 0.6430 - val_loss: 0.5763 - val_accuracy: 0.7005
Epoch 4/20
63/63 [==============================] - 5s 76ms/step - loss: 0.6032 - accuracy: 0.6650 - val_loss: 0.5684 - val_accuracy: 0.7054
Epoch 5/20
63/63 [==============================] - 5s 78ms/step - loss: 0.5952 - accuracy: 0.6715 - val_loss: 0.5675 - val_accuracy: 0.7153
Epoch 6/20
63/63 [==============================] - 5s 79ms/step - loss: 0.5883 - accuracy: 0.6820 - val_loss: 0.5759 - val_accuracy: 0.6918
Epoch 7/20
63/63 [==============================] - 5s 77ms/step - loss: 0.5672 - accuracy: 0.7015 - val_loss: 0.5548 - val_accuracy: 0.7166
Epoch 8/20
63/63 [==============================] - 5s 76ms/step - loss: 0.5568 - accuracy: 0.7215 - val_loss: 0.5715 - val_accuracy: 0.7005
Epoch 9/20
63/63 [==============================] - 5s 76ms/step - loss: 0.5540 - accuracy: 0.7110 - val_loss: 0.5535 - val_accuracy: 0.7191
Epoch 10/20
63/63 [==============================] - 5s 74ms/step - loss: 0.5538 - accuracy: 0.7140 - val_loss: 0.5632 - val_accuracy: 0.7141
Epoch 11/20
63/63 [==============================] - 5s 75ms/step - loss: 0.5443 - accuracy: 0.7285 - val_loss: 0.5357 - val_accuracy: 0.7389
Epoch 12/20
63/63 [==============================] - 5s 75ms/step - loss: 0.5342 - accuracy: 0.7205 - val_loss: 0.5484 - val_accuracy: 0.7153
Epoch 13/20
63/63 [==============================] - 5s 75ms/step - loss: 0.5377 - accuracy: 0.7225 - val_loss: 0.5587 - val_accuracy: 0.7215
Epoch 14/20
63/63 [==============================] - 5s 74ms/step - loss: 0.5258 - accuracy: 0.7305 - val_loss: 0.5697 - val_accuracy: 0.6968
Epoch 15/20
63/63 [==============================] - 5s 75ms/step - loss: 0.5371 - accuracy: 0.7175 - val_loss: 0.5322 - val_accuracy: 0.7438
Epoch 16/20
63/63 [==============================] - 5s 78ms/step - loss: 0.5156 - accuracy: 0.7380 - val_loss: 0.5582 - val_accuracy: 0.7277
Epoch 17/20
63/63 [==============================] - 5s 77ms/step - loss: 0.5134 - accuracy: 0.7445 - val_loss: 0.5330 - val_accuracy: 0.7364
Epoch 18/20
63/63 [==============================] - 5s 77ms/step - loss: 0.5038 - accuracy: 0.7530 - val_loss: 0.5304 - val_accuracy: 0.7463
Epoch 19/20
63/63 [==============================] - 5s 77ms/step - loss: 0.5128 - accuracy: 0.7405 - val_loss: 0.5458 - val_accuracy: 0.7339
Epoch 20/20
63/63 [==============================] - 5s 78ms/step - loss: 0.5071 - accuracy: 0.7470 - val_loss: 0.5302 - val_accuracy: 0.7401
```

```python
# plot the history of the accuracy on the training and validation sets
plt.plot(history3.history["accuracy"], label = "training")
plt.plot(history3.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```

![m6.png](/images/m6.png)

**The validation accuracy of this model during training ranges between %60 and %75.**

This model seems to perform better than model2 as to reaches a validation accuracy of about %75 while model2 only reached %70. Of course it also performs much better that model1. Although the validation accuracy for this model ranges between %60 and %75, it reaches %70 accuracy very quickly, and continues to produce accuracy above %70 with more epochs. It looks like this model does not overfit. We can see that the training accuracy and the validation accuracy are in the same range.

# §5. Transfer Learning

So far, we’ve been training models for distinguishing between cats and dogs from scratch. However, there are some already-trained models that can do related tasks. In the following cell, we will download `MobileNetV2` and configure it as a layer that can be included in our model.


```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```

Let's create out final `tf.keras.models.Sequential` model where we add `base_model_layer` as a layer. We will train our model, and visualize the training history as we did before. This time we don't need a lot of layers to have a good performance.


```python
# create model 4
model4 = models.Sequential([
    preprocessor,
    data_augmentation,               
    base_model_layer,
    layers.GlobalMaxPooling2D(),
    layers.Dropout(0.1),
    layers.Dense(2)
])

model4.summary() # show model 4 summary
```

```python
Model: "sequential_15"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 model (Functional)          (None, 160, 160, 3)       0         
                                                                 
 sequential_2 (Sequential)   (None, 160, 160, 3)       0         
                                                                 
 model_2 (Functional)        (None, 5, 5, 1280)        2257984   
                                                                 
 global_max_pooling2d_4 (Glo  (None, 1280)             0         
 balMaxPooling2D)                                                
                                                                 
 dropout_13 (Dropout)        (None, 1280)              0         
                                                                 
 dense_22 (Dense)            (None, 2)                 2562      
                                                                 
=================================================================
Total params: 2,260,546
Trainable params: 2,562
Non-trainable params: 2,257,984
_________________________________________________________________
```

We can see that there is a lot of complexity hidden in the `base_model_layer`. In this case we only train 2,562 parameters, but we also have 2,257,984 non-trainable parameters from `base_model_layer`.

Let's now train our final model and visualize accuracy.


```python
# compile model 4
model4.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
# train model 4
history4 = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data = validation_dataset)
```

```python
Epoch 1/20
63/63 [==============================] - 11s 105ms/step - loss: 0.8100 - accuracy: 0.7890 - val_loss: 0.1489 - val_accuracy: 0.9592
Epoch 2/20
63/63 [==============================] - 6s 90ms/step - loss: 0.5091 - accuracy: 0.8550 - val_loss: 0.1310 - val_accuracy: 0.9567
Epoch 3/20
63/63 [==============================] - 6s 90ms/step - loss: 0.4289 - accuracy: 0.8760 - val_loss: 0.1152 - val_accuracy: 0.9666
Epoch 4/20
63/63 [==============================] - 6s 91ms/step - loss: 0.3376 - accuracy: 0.9005 - val_loss: 0.1398 - val_accuracy: 0.9592
Epoch 5/20
63/63 [==============================] - 6s 90ms/step - loss: 0.3595 - accuracy: 0.8965 - val_loss: 0.1325 - val_accuracy: 0.9592
Epoch 6/20
63/63 [==============================] - 6s 91ms/step - loss: 0.3062 - accuracy: 0.9055 - val_loss: 0.1064 - val_accuracy: 0.9629
Epoch 7/20
63/63 [==============================] - 6s 89ms/step - loss: 0.3466 - accuracy: 0.8950 - val_loss: 0.1078 - val_accuracy: 0.9629
Epoch 8/20
63/63 [==============================] - 6s 89ms/step - loss: 0.2996 - accuracy: 0.9065 - val_loss: 0.1141 - val_accuracy: 0.9666
Epoch 9/20
63/63 [==============================] - 6s 89ms/step - loss: 0.3003 - accuracy: 0.9150 - val_loss: 0.1121 - val_accuracy: 0.9641
Epoch 10/20
63/63 [==============================] - 6s 90ms/step - loss: 0.2971 - accuracy: 0.9120 - val_loss: 0.1266 - val_accuracy: 0.9629
Epoch 11/20
63/63 [==============================] - 6s 91ms/step - loss: 0.3634 - accuracy: 0.8955 - val_loss: 0.1632 - val_accuracy: 0.9505
Epoch 12/20
63/63 [==============================] - 6s 89ms/step - loss: 0.3237 - accuracy: 0.9040 - val_loss: 0.1346 - val_accuracy: 0.9554
Epoch 13/20
63/63 [==============================] - 6s 90ms/step - loss: 0.2867 - accuracy: 0.9110 - val_loss: 0.1216 - val_accuracy: 0.9641
Epoch 14/20
63/63 [==============================] - 6s 90ms/step - loss: 0.2766 - accuracy: 0.9130 - val_loss: 0.0817 - val_accuracy: 0.9728
Epoch 15/20
63/63 [==============================] - 6s 90ms/step - loss: 0.3007 - accuracy: 0.9125 - val_loss: 0.0925 - val_accuracy: 0.9678
Epoch 16/20
63/63 [==============================] - 6s 91ms/step - loss: 0.2519 - accuracy: 0.9215 - val_loss: 0.0918 - val_accuracy: 0.9715
Epoch 17/20
63/63 [==============================] - 6s 90ms/step - loss: 0.2318 - accuracy: 0.9275 - val_loss: 0.1050 - val_accuracy: 0.9666
Epoch 18/20
63/63 [==============================] - 6s 90ms/step - loss: 0.2347 - accuracy: 0.9195 - val_loss: 0.0836 - val_accuracy: 0.9691
Epoch 19/20
63/63 [==============================] - 6s 89ms/step - loss: 0.2560 - accuracy: 0.9200 - val_loss: 0.1597 - val_accuracy: 0.9554
Epoch 20/20
63/63 [==============================] - 6s 90ms/step - loss: 0.2644 - accuracy: 0.9040 - val_loss: 0.1144 - val_accuracy: 0.9653
```

```python
# plot the history of the accuracy on the training and validation sets
plt.plot(history4.history["accuracy"], label = "training")
plt.plot(history4.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```

![m7.png](/images/m7.png)

**The validation accuracy of this model during training ranges between %96 and %97.5.**

Whoa!This model definitely much better than all the other models we created. We are now more that %20 better than the accuracy we got in model3 (which is the second best model). There is no We overfitting in model4, and the validation accuracy is even higher than the training accuracy.

# §6. Score on Test Data

Finally, let's evaluate the accuracy of model4 on the unseen `test_dataset`.


```python
loss, accuracy = model4.evaluate(test_dataset)
(loss, accuracy)
```

```python
6/6 [==============================] - 1s 63ms/step - loss: 0.0726 - accuracy: 0.9792
(0.07262241840362549, 0.9791666865348816)
```

We are able to achieve almost 98% accuracy on test data, which is very impressive!
